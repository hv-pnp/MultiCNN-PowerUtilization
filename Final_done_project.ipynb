{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCjfVi725uqRusuq5CkWSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ifwii/MultiCNN-PowerUtilization/blob/main/Final_done_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFA15-ijxJH-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import zipfile\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "WORD_EMBEDDING_SIZE = 50\n",
        "NEWS_FT = 'news_words'\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional,Conv1D,MaxPool1D,MaxPooling1D,GlobalMaxPooling1D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "\n",
        "!pip install prettytable\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "Registers = []\n",
        "Categorys = []\n",
        "\n",
        "with open(r\"C:example_1.csv\", 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        Categorys.append(row[1])\n",
        "        Register = row[0]\n",
        "        for word in STOPWORDS:\n",
        "            token = ' ' + word + ' '\n",
        "            Register = Register.replace(token, ' ')\n",
        "            Register = Register.replace(' ', ' ')\n",
        "            Register = Register.replace('_',' ')\n",
        "            Register = Register.replace('.',' ')\n",
        "        Registers.append(Register)\n",
        "print(len(Registers))\n",
        "print(len(Categorys))\n",
        "print(Registers)\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the register data\n",
        "vectorizer.fit(Registers)\n",
        "\n",
        "# Get the vocabulary count\n",
        "vocabulary_count = len(vectorizer.vocabulary_)\n",
        "\n",
        "print(\"Vocabulary count:\", vocabulary_count)"
      ],
      "metadata": {
        "id": "QbZBl9bYxoZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df=pd.DataFrame({\"Register\":Registers,\"Category\":Categorys})\n",
        "raw_df"
      ],
      "metadata": {
        "id": "Q9uND3_axrvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.info()"
      ],
      "metadata": {
        "id": "rwF7tsuHxvy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df.Category.unique(),print(\"\\n Total number of Unique Target Classes : \",raw_df.Category.nunique())\n"
      ],
      "metadata": {
        "id": "-QatnUocxxND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "REMOVE_NUM = re.compile('[\\d+]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    text: a string\n",
        "    return: modified initial string\n",
        "    \"\"\"\n",
        "    # lowercase text\n",
        "    text = text.lower() \n",
        "\n",
        "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) \n",
        "    \n",
        "    # Remove the XXXX values\n",
        "#     text = text.replace('x', '') \n",
        "    \n",
        "    # Remove white space\n",
        "    text = REMOVE_NUM.sub('', text)\n",
        "\n",
        "    #  delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) \n",
        "\n",
        "    # delete stopwords from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) \n",
        "    \n",
        "    # removes any words composed of less than 2 or more than 21 letters\n",
        "    text = ' '.join(word for word in text.split() if (len(word) >= 2 and len(word) <= 21))\n",
        "\n",
        "    # Stemming the words\n",
        "#     text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "CaZ087mAxzSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=raw_df"
      ],
      "metadata": {
        "id": "5hq8BViwx6Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Register']=dataset['Register'].apply(clean_text)\n",
        "dataset['Register']"
      ],
      "metadata": {
        "id": "6gncVwMxx84q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Register = dataset['Register'].values\n",
        "Category = dataset['Category'].values\n",
        "# print(labels)\n",
        "X_train,X_test,y_train,y_test = train_test_split(Register,Category, test_size = 0.20, random_state = 42)\n",
        "print(X_train.shape,X_test.shape)\n",
        "print(y_train.shape,y_test.shape)\n"
      ],
      "metadata": {
        "id": "vAs7rfx_x-Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape(-1,1)\n",
        "X_test=X_test.reshape(-1,1)\n",
        "y_train= y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "\n",
        "print(X_train.shape,X_test.shape)\n",
        "print(y_train.shape,y_test.shape)\n",
        "# print(y_test)\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "JEfgUCPTyAmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_title_size = int(sum([len(c) for c in dataset.Register])/dataset.shape[0])\n",
        "print(average_title_size)"
      ],
      "metadata": {
        "id": "2UwS1VCMyCwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's Fix Some Common Parameters :\n",
        "# The maximum number of words to be used. (most frequent)\n",
        "#vocab_size = 50000\n",
        "\n",
        "# Dimension of the dense embedding.\n",
        "embedding_dim = 128\n",
        "\n",
        "# Max number of words in each complaint.\n",
        "#max_length = 200\n",
        "\n",
        "# Truncate and padding options\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'"
      ],
      "metadata": {
        "id": "2BEGDhHTyEMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenising , Converting Text To Sequences and Padding Our Data : \n",
        "\n",
        "#tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.flatten())\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)\n",
        "max_length = max([len(text) for text in X_train])\n",
        "\n",
        "print(max_length)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "word_index"
      ],
      "metadata": {
        "id": "nCqOl9omyGgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting into Text to sequences and padding :\n",
        "train_seq = tokenizer.texts_to_sequences(X_train.flatten())\n",
        "train_padded = pad_sequences(train_seq, maxlen=average_title_size, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "validation_seq = tokenizer.texts_to_sequences(X_test.flatten())\n",
        "validation_padded = pad_sequences(validation_seq, maxlen=average_title_size, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "B7dzj2s2yInK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[3],train_seq[3],train_padded[3]\n",
        "X_test[3],validation_seq[3],validation_padded[3]"
      ],
      "metadata": {
        "id": "f8X-0MP3yKK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of data tensor:', train_padded.shape)\n",
        "print('Shape of data tensor:', validation_padded.shape)"
      ],
      "metadata": {
        "id": "9BUHsL-YyNP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "RGxixHt4yOuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = OneHotEncoder()\n",
        "training_labels = encode.fit_transform(y_train)\n",
        "\n",
        "validation_labels = encode.transform(y_test)"
      ],
      "metadata": {
        "id": "xEJosapLyRMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_labels)"
      ],
      "metadata": {
        "id": "zWnhqmGrySpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_padded.shape)\n",
        "print(validation_labels.shape)\n",
        "print(validation_padded.shape)\n",
        "print(training_labels.shape)\n",
        "print(type(train_padded))\n",
        "print(type(validation_padded))\n",
        "print(type(training_labels))\n",
        "print(type(validation_labels))\n",
        "\n",
        "\n",
        "\n",
        "# The labels must be converted to arrays\n",
        "# Convert the labels to arrays\n",
        "training_labels = training_labels.toarray()\n",
        "validation_labels = validation_labels.toarray()\n",
        "\n",
        "print(type(training_labels))\n",
        "print(type(validation_labels))"
      ],
      "metadata": {
        "id": "RmHlXQgRyWSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history):\n",
        "  plt.title('Loss VS Accuracy')\n",
        "  plt.plot(history.history['loss'], label='train loss')\n",
        "  plt.plot(history.history['val_loss'], label='test loss')\n",
        "  plt.legend()\n",
        "  \n",
        "  plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='test accuracy')\n",
        "  plt.legend()\n",
        "  plt.savefig(r\"C:\\my_line1_chart.png\")  \n",
        "  plt.show();\n",
        "  return None\n",
        "def loss_graph(history):\n",
        "  plt.title('Loss')\n",
        "  plt.plot(history.history['loss'], label='train')\n",
        "  plt.plot(history.history['val_loss'], label='test')\n",
        "  plt.legend()\n",
        "  plt.savefig(r\"C:\\my_line2_chart.png\")  \n",
        "  plt.show();\n",
        "  \n",
        "  return None\n",
        "\n",
        "def acc_graph(history):\n",
        "  plt.title('Accuracy')\n",
        "  plt.plot(history.history['accuracy'], label='train')\n",
        "  plt.plot(history.history['val_accuracy'], label='test')\n",
        "  plt.legend()\n",
        "  plt.savefig(r\"C:\\my_line3_chart.png\")  \n",
        "  plt.show();\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def evaluate_preds(y_true, y_preds):\n",
        "    \"\"\"\n",
        "    Performs evaluation comparison on y_true labels vs. y_pred labels\n",
        "    on a classification.\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_preds)\n",
        "    precision = precision_score(y_true, y_preds, average='micro')\n",
        "    recall = recall_score(y_true, y_preds, average='micro')\n",
        "    f1 = f1_score(y_true, y_preds, average='micro')\n",
        "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
        "                   \"precision\": round(precision, 2),\n",
        "                   \"recall\": round(recall, 2),\n",
        "                   \"f1\": round(f1, 2)}\n",
        "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1 score: {f1:.2f}\")\n",
        "    \n",
        "    return metric_dict\n",
        "\n",
        "def model_eval(model,a,b,c,d):\n",
        "  score=model.evaluate(a,b,verbose=0)\n",
        "  score1=model.evaluate(c,d,verbose=0)\n",
        "  print(\"\\n\")\n",
        "  print(\"Model Loss on training data \",score[0])\n",
        "  print(\"Model Accuracy on training data: \",score[1])\n",
        "  print(\"Model Loss on validation data\",score1[0])\n",
        "  print(\"Model Accuracy on validation data: \",score1[1])\n",
        "  print(\"\\n\")\n",
        "  return score,score1\n",
        "\n",
        "def model_eval(model,a,b,c,d):\n",
        "  score=model.evaluate(a,b,verbose=0)\n",
        "  score1=model.evaluate(c,d,verbose=0)\n",
        "  print(\"\\n\")\n",
        "  print(\"Model Loss on training data \",score[0])\n",
        "  print(\"Model Accuracy on training data: \",score[1])\n",
        "  print(\"Model Loss on validation data\",score1[0])\n",
        "  print(\"Model Accuracy on validation data: \",score1[1])\n",
        "  print(\"\\n\")\n",
        "  return score,score1\n"
      ],
      "metadata": {
        "id": "oWG9nzgnyaoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "tf.keras.backend.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size,embedding_dim,input_length=train_padded.shape[1]))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Bidirectional(LSTM(embedding_dim)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(41, activation='softmax'))\n",
        "model.summary()\n",
        "optim=tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.05, momentum=0.5, nesterov=True, name=\"SGD\"\n",
        ")\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optim,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "filepath=\"weights_best_bi_lstms_n_cnn.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
        "start = time.perf_counter()\n",
        "callbacks_list = [checkpoint,EarlyStopping(monitor='val_accuracy', mode='max', patience=10, verbose=1)]\n",
        "\n",
        "\n",
        "history = model.fit(train_padded, training_labels, shuffle=True ,\n",
        "                    epochs=epochs, batch_size=batch_size, \n",
        "                    callbacks=callbacks_list,validation_data=(validation_padded, validation_labels))\n",
        "t23 = time.perf_counter() - start\n",
        "print('Total time took for training %.3f seconds.' % t23)\n",
        "hist23=history\n",
        "\n",
        "plot_graphs(hist23),loss_graph(hist23),acc_graph(hist23)"
      ],
      "metadata": {
        "id": "4qdMzqZiycob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = model.predict(validation_padded)\n",
        "evaluate_preds(np.argmax(validation_labels, axis=1),np.argmax(predicted, axis=1))"
      ],
      "metadata": {
        "id": "NjgMww-oyeb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_english.h5\")\n"
      ],
      "metadata": {
        "id": "uE-UnvbMykAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
       
        "Registers = []\n",
        "Categorys = []\n",
        "\n",
        "with open(r\"C:\\Test_data.csv\", 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        Categorys.append(row[1])\n",
        "        Register = row[0]\n",
        "        for word in STOPWORDS:\n",
        "            token = ' ' + word + ' '\n",
        "            Register = Register.replace(token, ' ')\n",
        "            Register = Register.replace(' ', ' ')\n",
        "            Register = Register.replace('_',' ')\n",
        "            Register = Register.replace('.',' ')\n",
        "        Registers.append(Register)\n",
        "correct_predictions = 0\n",
        "total_predictions = len(Registers)\n",
        "for i in range(len(Registers)):\n",
        "    new_text = [clean_text(Registers[i])]\n",
        "    print(new_text)\n",
        "    seq = tokenizer.texts_to_sequences(new_text)\n",
        "    padded = pad_sequences(seq, maxlen=average_title_size, padding=padding_type, truncating=trunc_type)\n",
        "    pred = model.predict(padded)\n",
        "    \n",
        "    predicted_label = encode.inverse_transform(pred)\n",
        "    \n",
        "    predicted_category_id = np.argmax(pred)\n",
        "    \n",
        "    actual_category_id = Categorys[i] \n",
        "    \n",
        "    if predicted_label == actual_category_id:\n",
        "        correct_predictions += 1\n",
        "    \n",
        "    #acc = np.argmax(pred,axis=1)\n",
        "    #predicted_label = encode.inverse_transform(pred)\n",
        "    #print(predicted_label)\n",
        "    #print(f'Product category id: {np.argmax(pred[0])}')\n",
        "    #print(f'Predicted label is: {predicted_label[0]}')\n",
        "    \n",
        "    print(f'Product category id: {actual_category_id}')\n",
        "    print(f'Predicted label is: {predicted_label[0]}')\n",
        "    \n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "    \n",
        "#print(f'Accuracy score: { acc.max() * 100}')\n",
        "print(f'Accuracy score: {accuracy}%')\n"
      ],
      "metadata": {
        "id": "7oYsnufnymza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Reg = input(\"Enter the register name: \")\n",
        "token = ' ' +Reg + ' '\n",
        "Reg = Reg.replace(token, ' ')\n",
        "Reg = Reg.replace(' ', ' ')\n",
        "Reg = Reg.replace('_',' ')\n",
        "Reg = Reg.replace('.',' ')\n",
        "\n",
        "new_text = [clean_text(Reg)]\n",
        "seq = tokenizer.texts_to_sequences(new_text)\n",
        "padded = pad_sequences(seq, maxlen=average_title_size, padding=padding_type, truncating=trunc_type)\n",
        "pred = model.predict(padded)\n",
        "acc = np.argmax(pred,axis=1)\n",
        "predicted_label = encode.inverse_transform(pred)\n",
        "print(f'Predicted label is: {predicted_label[0]}')\n",
        "print(f'Accuracy score: {acc.max() * 100}')"
      ],
      "metadata": {
        "id": "OL64uk5myoQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
